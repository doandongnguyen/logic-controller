{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The environment used for expriemnts:\n",
    "A navigation task: here the agent should reach the target without colliding with the obstacle within limited steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "import random\n",
    "\n",
    "class move_gym():\n",
    "    def __init__(self):\n",
    "        self.scope = 2.0\n",
    "        self.states = 6\n",
    "        self.actions = 4\n",
    "    def reset(self, s=[]):\n",
    "        if np.array( s ).shape[0] == 0:\n",
    "            self.obstacle_x = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1\n",
    "            self.obstacle_y = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1\n",
    "\n",
    "            self.move_x = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1\n",
    "            self.move_y = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1  \n",
    "            while ( abs(self.obstacle_x-self.move_x) < 1.05 ) & ( abs(self.obstacle_y-self.move_y) < 1.05 ):\n",
    "                self.move_x = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1\n",
    "                self.move_y = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1      \n",
    "\n",
    "            self.target_x = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1\n",
    "            self.target_y = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1\n",
    "            while (  ( abs(self.obstacle_x-self.target_x) < 1.05 ) & ( abs(self.obstacle_y-self.target_y) < 1.05 )  ) |\\\n",
    "             (  ( abs(self.move_x-self.target_x) < 1.05 ) & ( abs(self.move_y-self.target_y) < 1.05 )  ):\n",
    "                self.target_x = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1\n",
    "                self.target_y = np.random.randint( int(-self.scope*10), int(self.scope*10) )*0.1        \n",
    "        else:\n",
    "            self.obstacle_x=s[0]\n",
    "            self.obstacle_y=s[1]\n",
    "            self.target_x=s[2]\n",
    "            self.target_y=s[3]\n",
    "            self.move_x=s[4]\n",
    "            self.move_y=s[5]\n",
    "\n",
    "        state=np.array([ self.obstacle_x, self.obstacle_y, self.target_x, self.target_y, self.move_x, self.move_y ])\n",
    "        return state #, self.state2img(state)\n",
    "    def step(self, action):\n",
    "        velocity = 0.2\n",
    "        if action==0: # up down right left\n",
    "            self.move_y+=velocity\n",
    "        if action==1:\n",
    "            self.move_y-=velocity\n",
    "        if action==2:\n",
    "            self.move_x+=velocity\n",
    "        if action==3:\n",
    "            self.move_x-=velocity\n",
    "\n",
    "#         if self.move_x > (self.scope+1.0):\n",
    "#             self.move_x-=velocity\n",
    "#         if self.move_x < (-self.scope-1.0):\n",
    "#             self.move_x+=velocity\n",
    "#         if self.move_y > (self.scope+1.0):\n",
    "#             self.move_y-=velocity\n",
    "#         if self.move_y < (-self.scope-1.0):\n",
    "#             self.move_y+=velocity\n",
    "        \n",
    "        reward = -0.1\n",
    "        done = False\n",
    "        info = \"^_^\"\n",
    "        if (  ( abs(self.obstacle_x-self.move_x) < 1.05 ) & ( abs(self.obstacle_y-self.move_y) < 1.05 )  ): \n",
    "            reward = -1.0 \n",
    "            done = True\n",
    "            info = \"collision\"\n",
    "\n",
    "        elif (  ( abs(self.target_x-self.move_x) < 1.05 ) & ( abs(self.target_y-self.move_y) < 1.05 )  ):\n",
    "            reward = 1.0\n",
    "            done = True\n",
    "            info = \"reach\"\n",
    "\n",
    "        state=np.array([ self.obstacle_x, self.obstacle_y, self.target_x, self.target_y, self.move_x, self.move_y ])\n",
    "\n",
    "        return state, reward,done,info\n",
    "    def state2img(self, state):\n",
    "        img = np.zeros([84,84,3], dtype=np.uint8)\n",
    "        ( img[ int(42-(self.obstacle_y+0.5)*10):int(42-(self.obstacle_y-0.5)*10), int((self.obstacle_x-0.5)*10+42):int((self.obstacle_x+0.5)*10+42),2 ] ).fill(255)\n",
    "        ( img[ int(42-(self.target_y+0.5)*10):int(42-(self.target_y-0.5)*10), int((self.target_x-0.5)*10+42):int((self.target_x+0.5)*10+42),1 ] ).fill(255)\n",
    "        ( img[ int(42-(self.move_y+0.5)*10):int(42-(self.move_y-0.5)*10), int((self.move_x-0.5)*10+42):int((self.move_x+0.5)*10+42),0 ] ).fill(255)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "env = move_gym() # initialize env\n",
    "STEP = 50 # Step limitation in an episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logic_q = np.load( '../logic_q-1.02-4-adjust-10.npy' )\n",
    "discrete = np.array( [0., 1.02, 1.86, 2.93, 4.1, 95.03] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discrete_it(state, discrete):\n",
    "    \n",
    "    dis_s = []\n",
    "    for i in xrange( len(state) ):\n",
    "        num = state[i]\n",
    "        over = num - discrete\n",
    "        for j in xrange( len(over) ):\n",
    "            if over[j]<0:\n",
    "                over[j] = 100 # a certain big number\n",
    "        dis_s.append( np.argmin( over ) )\n",
    "    return dis_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def state2relative(state):\n",
    "    obstacle = np.array( state[0] )\n",
    "    target = np.array( state[1] )\n",
    "    agent = np.array( state[2][0] )\n",
    "#     print agent\n",
    "    \n",
    "    top_t = 100.0\n",
    "    bottom_t = 100.0\n",
    "    right_t = 100.0\n",
    "    left_t = 100.0\n",
    "\n",
    "    top_o = 100.0\n",
    "    bottom_o = 100.0\n",
    "    right_o = 100.0\n",
    "    left_o = 100.0        \n",
    "#     print obstacle\n",
    "#     print obstacle[:,1]\n",
    "#     print abs(obstacle[:,1]-agent[1])\n",
    "    obstacle_x=obstacle[np.argmin( abs(obstacle[:,0]-agent[0]) ),0]\n",
    "    obstacle_y=obstacle[np.argmin( abs(obstacle[:,1]-agent[1]) ),1]\n",
    "    target_x=target[np.argmin( abs(target[:,0]-agent[0]) ),0]\n",
    "    target_y=target[np.argmin( abs(target[:,1]-agent[1]) ),1]\n",
    "    move_x=agent[0]\n",
    "    move_y=agent[1]\n",
    "\n",
    "    if target_y >= move_y:\n",
    "        top_t = target_y - move_y\n",
    "    if target_y < move_y:\n",
    "        bottom_t = move_y - target_y\n",
    "    if target_x >= move_x:\n",
    "        right_t = target_x - move_x\n",
    "    if target_x < move_x:\n",
    "        left_t = move_x - target_x\n",
    "\n",
    "    if obstacle_y >= move_y:\n",
    "        top_o = obstacle_y - move_y\n",
    "    if obstacle_y < move_y:\n",
    "        bottom_o = move_y - obstacle_y\n",
    "    if obstacle_x >= move_x:\n",
    "        right_o = obstacle_x - move_x\n",
    "    if obstacle_x < move_x:\n",
    "        left_o = move_x - obstacle_x\n",
    "\n",
    "    return np.array([ top_t, bottom_t, right_t, left_t, top_o, bottom_o, right_o, left_o ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Here is the test for fuzzy logic controller\n",
    "explanation for the output:  \n",
    "- -- 3 ->:\n",
    "```\n",
    "the action is 3, and it represents 'move left'. (up: 0, down: 1, right: 2, left: 3)\n",
    "```\n",
    "- info:  reach:\n",
    "```\n",
    "'reach' means the agent has reached the target within limited steps.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30000000000000004, 1.5, -0.2, -0.1, -1.8, -0.30000000000000004] [0, 5, 1, 5, 1, 5, 1, 5]\n",
      "-- 2 -> [-0.30000000000000004, 1.5, -0.2, -0.1, -1.6, -0.30000000000000004] [0, 5, 1, 5, 1, 5, 1, 5]\n",
      "-- 2 -> [-0.30000000000000004, 1.5, -0.2, -0.1, -1.4000000000000001, -0.30000000000000004] [0, 5, 1, 5, 1, 5, 1, 5]\n",
      "-- 2 -> [-0.30000000000000004, 1.5, -0.2, -0.1, -1.2000000000000002, -0.30000000000000004] info:  reach\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = env.reset(  )\n",
    "obstacle_02=[state[0:2]]\n",
    "A = [state]\n",
    "old_action = 1.5\n",
    "print state.tolist(),\n",
    "for j in xrange(STEP):\n",
    "    relative_state=state2relative( [ obstacle_02, [state[2:4]], [state[4:]] ] )\n",
    "    # discrete it:\n",
    "    relative_state = discrete_it( relative_state, discrete )\n",
    "    print relative_state\n",
    "    action = np.argmax( logic_q[relative_state[0]][relative_state[1]][relative_state[2]][relative_state[3]]\\\n",
    "    [relative_state[4]][relative_state[5]][relative_state[6]][relative_state[7]] )-1\n",
    "    \n",
    "    if (((relative_state[0]+relative_state[4])==0) | ((relative_state[1]+relative_state[5])==0)) & (action<1.2) & (old_action<1.2):\n",
    "    #             print \"^^^\"\n",
    "        action = old_action\n",
    "    if (((relative_state[2]+relative_state[6])==0) | ((relative_state[3]+relative_state[7])==0)) & (action>1.8) & (old_action>1.8):\n",
    "    #             print \"%%%\"\n",
    "        action = old_action\n",
    "\n",
    "    old_action = action\n",
    "    \n",
    "    state, reward,done,info = env.step(action)\n",
    "    A.append(state)\n",
    "    print '--', action, '->', state.tolist(),\n",
    "    if done:\n",
    "        print \"info: \", info\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Here we plot the move path of the agent:\n",
    "- blue block: agent\n",
    "- red block: obstacle\n",
    "- green block: target\n",
    "- white line: move path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAFpCAYAAACI3gMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkxEaSPjJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cec30ce90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    i=0\n",
    "    fig = plt.figure( figsize=(6,6) )\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (-3, -3),\n",
    "            6,\n",
    "            6,\n",
    "            color=\"grey\"\n",
    "        )\n",
    "    )\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (-2, -2),\n",
    "            4,\n",
    "            4,\n",
    "            color=\"black\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    s=np.array( A[i] )\n",
    "    \n",
    "    for i in range( len(obstacle_02) ):\n",
    "        ax.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (A[0][0]-0.5, A[0][1]-0.5),\n",
    "                1,\n",
    "                1,\n",
    "                color=\"red\",\n",
    "                hatch=\"x\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "#     ax.add_patch(\n",
    "#         patches.Rectangle(\n",
    "#             (s[0]-0.5, s[1]-0.5),\n",
    "#             1,\n",
    "#             1,\n",
    "#             color=\"red\",\n",
    "#             hatch=\"x\"\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (A[0][2]-0.5, A[0][3]-0.5),\n",
    "            1,\n",
    "            1,\n",
    "            color=\"green\",\n",
    "            hatch=\"+\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(\n",
    "            (A[0][4]-0.5, A[0][5]-0.5),\n",
    "            1,\n",
    "            1,\n",
    "            color=\"blue\",\n",
    "            hatch=\".\"\n",
    "        )\n",
    "    )\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_ylim(-4, 4)\n",
    "#     plt.grid(True)\n",
    "    \n",
    "    for i in xrange( len(A)-1 ):\n",
    "        ax.plot( [A[i][4], A[i+1][4]], [A[i][5], A[i+1][5]], color=\"white\", linewidth=2)#plot lines\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    reward_keep=[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Next, the success rate of the fuzzy logic controller\n",
    "You might care about the success rate of this fuzzy logic controller. Here we will show it with 100 thousand tests.  \n",
    "The agent should reach the target in all tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [08:11<00:00, 2035.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of 'just wasting steps':  0 number of collision:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "B = []\n",
    "B1 = []\n",
    "for i in trange( 1000000 ):\n",
    "    state = env.reset(  )\n",
    "    obstacle_02=[state[0:2]]\n",
    "    A = state\n",
    "    old_action = 1.5\n",
    "    for j in xrange(STEP):\n",
    "\n",
    "        relative_state = state2relative( [ obstacle_02, [state[2:4]], [state[4:]] ] )\n",
    "        # discrete it:\n",
    "        relative_state = discrete_it( relative_state, discrete )\n",
    "\n",
    "        action = np.argmax( logic_q[relative_state[0]][relative_state[1]][relative_state[2]][relative_state[3]]\\\n",
    "        [relative_state[4]][relative_state[5]][relative_state[6]][relative_state[7]] ) - 1\n",
    "        \n",
    "        \n",
    "        if (((relative_state[0]+relative_state[4])==0) | ((relative_state[1]+relative_state[5])==0)) & (action<1.2) & (old_action<1.2):\n",
    "#             print \"^^^\"\n",
    "            action = old_action\n",
    "        if (((relative_state[2]+relative_state[6])==0) | ((relative_state[3]+relative_state[7])==0)) & (action>1.8) & (old_action>1.8):\n",
    "#             print \"%%%\"\n",
    "            action = old_action\n",
    "        \n",
    "        old_action = action\n",
    "        state, reward,done,info = env.step(action)\n",
    "        if done:\n",
    "            if info==\"collision\":\n",
    "                B1.append(A)\n",
    "            break\n",
    "    if done == 0:\n",
    "        B.append(A)\n",
    "\n",
    "print \"number of 'just wasting steps': \", len(B), \"number of collision: \", len(B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
